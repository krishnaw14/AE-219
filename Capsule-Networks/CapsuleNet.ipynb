{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-fbc87836fcb1>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/krishna/.edm/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/krishna/.edm/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/krishna/.edm/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/krishna/.edm/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/krishna/.edm/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#Loading the MNIST dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('/tmp/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13003f978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing the dataset\n",
    "n_samples = 5\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = mnist.train.images[index].reshape(28, 28)\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, 6, 1], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Layer for the images\n",
    "X = tf.placeholder(shape=[None,28,28,1], dtype = tf.float32, name= \"X\")\n",
    "#None for batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primary Capsule Layer\n",
    "caps1_n_maps = 32\n",
    "caps1_n_caps = caps1_n_maps*6*6 #1152 primary capsule units\n",
    "caps1_n_dims = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_params = {\n",
    "    \"filters\": 256,\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(X, name = 'conv1', **conv1_params)\n",
    "conv2 = tf.layers.conv2d(conv1, name = \"conv2\", **conv2_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of Output of conv2: (batch_size, 6, 6, 32, 8) \n",
    "# Since this first capsule layer will be fully connected to the next capsule layer, we can simply flatten the 6×6 grids\n",
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims], name = 'caps1_raw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(s, epsilon = 1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name = 'squash'):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=-1, keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm+epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor*unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Digit Caps\n",
    "caps2_n_cap = 10\n",
    "caps2_n_dims = 16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
